# -*- coding: utf-8 -*-
"""Mini AI analisis obat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pib2kxKLOGXtcPSJwCWsvH-8f7rGyQA5
"""

"""
Streamlit app: Dashboard Analisis Obat (Multifungsi)
File: dashboard_analisis_obat.py

Deskripsi singkat:
- Aplikasi ini memungkinkan pengguna untuk mengunggah data (CSV) atau memasukkan SMILES molekul.
- Bila RDKit tersedia, aplikasi akan menghitung deskriptor kimia dasar dari SMILES.
- Mendukung klasifikasi multi-kelas (jenis obat) menggunakan RandomForest atau Neural Network (pilihan).
- Menampilkan metrik evaluasi (accuracy, precision/recall/f1 per kelas), confusion matrix, ROC (biner/one-vs-rest), visualisasi embedding (PCA/UMAP), feature importance, dan tabel hasil prediksi.
- Menyediakan opsi unduh hasil dan model.

Cara pakai singkat:
1) (Direkomendasikan) Buat virtualenv/conda env.
2) Install dependensi dasar:
   pip install streamlit pandas scikit-learn matplotlib plotly joblib umap-learn
   Untuk TensorFlow: pip install tensorflow
   Untuk RDKit (opsional, direkomendasikan via conda): conda install -c conda-forge rdkit
3) Jalankan: streamlit run dashboard_analisis_obat.py

Catatan: RDKit opsional. Jika tidak ada, app masih bekerja dengan data numerik yang Anda unggah.
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
import joblib
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Optional imports
try:
    from rdkit import Chem
    from rdkit.Chem import Descriptors
    RDKit_AVAILABLE = True
except Exception:
    RDKit_AVAILABLE = False

try:
    import umap
    UMAP_AVAILABLE = True
except Exception:
    UMAP_AVAILABLE = False

st.set_page_config(page_title="Dashboard Analisis Jenis Obat", layout="wide")
st.title("Dashboard AI: Analisis Jenis Obat")
st.markdown("Aplikasi demo untuk ekstraksi deskriptor (jika ada SMILES), pelatihan model klasifikasi, dan visualisasi hasil.")

# Sidebar - upload & options
st.sidebar.header("Data & Pengaturan")
uploaded_file = st.sidebar.file_uploader("Unggah CSV (harus berisi fitur numerik atau kolom SMILES + label)", type=['csv'])
use_example = st.sidebar.checkbox('Gunakan contoh dataset sintetis', value=True)
smiles_input = st.sidebar.text_area('Masukkan SMILES (optional, satu per baris untuk prediksi cepat)', value='')
model_choice = st.sidebar.selectbox('Model', ['RandomForest (default)', 'NeuralNetwork (Keras)'])
random_state = int(st.sidebar.number_input('Random seed', value=42, step=1))
train_frac = st.sidebar.slider('Proporsi data untuk train', 0.1, 0.9, 0.75)
run_train = st.sidebar.button('Latih model')

st.sidebar.markdown('---')
if RDKit_AVAILABLE:
    st.sidebar.success('RDKit tersedia: SMILES â†’ deskriptor ON')
else:
    st.sidebar.info('RDKit tidak terdeteksi. Jika ingin ekstraksi deskriptor dari SMILES, install RDKit (conda).')

# Helper: sample dataset
@st.cache_data
def generate_example(n=300, random_state=42):
    rng = np.random.RandomState(random_state)
    # buat 3 kelas obat: Analgesik, Antibiotik, Antihipertensi (labels: Analgesik/Antibiotik/Antihipertensi)
    classes = ['Analgesik','Antibiotik','Antihipertensi']
    data = []
    for cls in classes:
        if cls == 'Analgesik':
            mw = rng.normal(300, 30, n)
            logP = rng.normal(2.5, 0.8, n)
        elif cls == 'Antibiotik':
            mw = rng.normal(450, 50, n)
            logP = rng.normal(1.5, 1.0, n)
        else:
            mw = rng.normal(350, 40, n)
            logP = rng.normal(3.0, 1.0, n)
        h_donors = rng.poisson(2, n)
        h_acceptors = rng.poisson(5, n)
        polar = rng.normal(80, 15, n)
        for i in range(n):
            data.append([mw[i], logP[i], h_donors[i], h_acceptors[i], polar[i], cls])
    df = pd.DataFrame(data, columns=['mw','logP','h_donors','h_acceptors','polar_surface','label'])
    return df.sample(frac=1, random_state=random_state).reset_index(drop=True)

# Helper: compute simple RDKit descriptors
def rdkit_descriptors_from_smiles(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    desc = {
        'MolWt': Descriptors.MolWt(mol),
        'LogP': Descriptors.MolLogP(mol),
        'HDonors': Descriptors.NumHDonors(mol),
        'HAcceptors': Descriptors.NumHAcceptors(mol),
        'TPSA': Descriptors.TPSA(mol),
        'RotatableBonds': Descriptors.NumRotatableBonds(mol)
    }
    return desc

# Load data
if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success('CSV berhasil diunggah.')
    except Exception as e:
        st.error(f'Gagal membaca CSV: {e}')
        st.stop()
elif use_example:
    df = generate_example(n=150, random_state=random_state)
    st.info('Menggunakan dataset contoh sintetis.')
else:
    st.warning('Tidak ada data tersedia. Unggah CSV atau aktifkan contoh dataset.')
    st.stop()

st.subheader('Preview data (10 baris pertama)')
st.dataframe(df.head(10))

# Detect columns
cols = df.columns.tolist()
label_col = None
smiles_col = None
for c in cols:
    if c.lower() in ['label','jenis','class','target']:
        label_col = c
    if c.lower() in ['smiles','smile']:
        smiles_col = c

if label_col:
    st.write(f'Kolom label terdeteksi: **{label_col}**')
else:
    st.warning('Tidak terdeteksi kolom label. Anda harus punya kolom label untuk pelatihan (nama umum: label/jenis/class).')

if smiles_col:
    st.write(f'Kolom SMILES terdeteksi: **{smiles_col}**')

# If SMILES present and RDKit available, compute descriptors
if smiles_col and RDKit_AVAILABLE:
    st.info('Menghitung deskriptor dari SMILES menggunakan RDKit...')
    desc_list = []
    bad_idx = []
    for idx, smi in enumerate(df[smiles_col].astype(str)):
        d = rdkit_descriptors_from_smiles(smi)
        if d is None:
            bad_idx.append(idx)
            desc_list.append({'MolWt':np.nan,'LogP':np.nan,'HDonors':np.nan,'HAcceptors':np.nan,'TPSA':np.nan,'RotatableBonds':np.nan})
        else:
            desc_list.append(d)
    desc_df = pd.DataFrame(desc_list)
    df = pd.concat([df.reset_index(drop=True), desc_df.reset_index(drop=True)], axis=1)
    if bad_idx:
        st.warning(f'{len(bad_idx)} SMILES tidak valid dan diberi NaN pada deskriptor (baris: {bad_idx[:10]}...).')

# Feature selection: default numeric columns excluding label
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
if label_col in numeric_cols:
    numeric_cols.remove(label_col)

st.sidebar.header('Fitur & pra-proses')
selected_features = st.sidebar.multiselect('Pilih fitur numerik untuk model', options=numeric_cols, default=numeric_cols)
fill_na = st.sidebar.selectbox('Cara mengisi NA', ['drop rows with NA','fill with median','fill with mean'], index=1)
scale = st.sidebar.checkbox('Scale fitur (StandardScaler)', value=True)

if not selected_features:
    st.error('Pilih setidaknya satu fitur numerik untuk model.')
    st.stop()

# Prepare X,y
X = df[selected_features].copy()
if label_col is None:
    st.error('Tidak ada kolom label. Tidak bisa melatih model tanpa label.')
    st.stop()

y_raw = df[label_col].astype(str).copy()
le = LabelEncoder()
y = le.fit_transform(y_raw)
class_names = le.classes_

# Handle NA
if fill_na == 'drop rows with NA':
    keep = X.dropna().index
    X = X.loc[keep].reset_index(drop=True)
    y = y[keep]
else:
    if fill_na == 'fill with median':
        X = X.fillna(X.median())
    else:
        X = X.fillna(X.mean())

# Split
if run_train:
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_frac, stratify=y, random_state=random_state)

    # Scale
    if scale:
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(X_train)
        X_test_s = scaler.transform(X_test)
    else:
        scaler = None
        X_train_s = X_train.values
        X_test_s = X_test.values

    # Train model
    if model_choice.startswith('RandomForest'):
        model = RandomForestClassifier(n_estimators=300, random_state=random_state)
        model.fit(X_train_s, y_train)
        y_pred = model.predict(X_test_s)
        y_proba = model.predict_proba(X_test_s) if hasattr(model, 'predict_proba') else None
    else:
        # Keras simple feedforward
        try:
            import tensorflow as tf
            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Dense, Dropout
            from tensorflow.keras.utils import to_categorical
        except Exception as e:
            st.error('TensorFlow tidak tersedia. Install tensorflow untuk memakai NeuralNetwork.')
            st.stop()
        n_classes = len(class_names)
        y_train_cat = to_categorical(y_train, num_classes=n_classes)
        y_test_cat = to_categorical(y_test, num_classes=n_classes)
        input_dim = X_train_s.shape[1]
        nn = Sequential([Dense(128, activation='relu', input_shape=(input_dim,)), Dropout(0.2), Dense(64, activation='relu'), Dense(n_classes, activation='softmax')])
        nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        nn.fit(X_train_s, y_train_cat, epochs=30, batch_size=32, validation_split=0.1, verbose=0)
        y_proba = nn.predict(X_test_s)
        y_pred = np.argmax(y_proba, axis=1)
        model = nn

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    st.subheader('Hasil Evaluasi')
    st.write(f'Akurasi pada data test: **{acc:.3f}**')
    st.text('Classification report:')
    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose())

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(6,5))
    cax = ax.matshow(cm, cmap='Blues')
    fig.colorbar(cax)
    ax.set_xticks(range(len(class_names)))
    ax.set_yticks(range(len(class_names)))
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.set_yticklabels(class_names)
    for (i, j), z in np.ndenumerate(cm):
        ax.text(j, i, str(z), ha='center', va='center')
    ax.set_xlabel('Predicted'); ax.set_ylabel('Actual')
    st.pyplot(fig)

    # Feature importance (if RF)
    if model_choice.startswith('RandomForest'):
        fi = pd.Series(model.feature_importances_, index=selected_features).sort_values(ascending=False)
        st.subheader('Feature importance (RandomForest)')
        st.bar_chart(fi)

    # Embedding: PCA or UMAP
    st.subheader('Visualisasi embedding (2D)')
    if UMAP_AVAILABLE:
        reducer = umap.UMAP(random_state=random_state)
        embedding = reducer.fit_transform(X_test_s)
        title_txt = 'UMAP'
    else:
        pca = PCA(n_components=2, random_state=random_state)
        embedding = pca.fit_transform(X_test_s)
        title_txt = 'PCA'
    emb_df = pd.DataFrame(embedding, columns=['dim1','dim2'])
    emb_df['actual'] = [class_names[i] for i in y_test]
    emb_df['predicted'] = [class_names[i] for i in y_pred]
    fig2, ax2 = plt.subplots()
    for cls in np.unique(y_test):
        mask = y_test == cls
        ax2.scatter(emb_df.loc[mask,'dim1'], emb_df.loc[mask,'dim2'], label=class_names[cls], alpha=0.6)
    ax2.legend()
    ax2.set_title(title_txt)
    st.pyplot(fig2)

    # Show sample prediction table
    st.subheader('Tabel hasil prediksi (test set sample)')
    res = X_test.reset_index(drop=True).copy()
    res['actual'] = [class_names[i] for i in y_test]
    res['predicted'] = [class_names[i] for i in y_pred]
    if y_proba is not None:
        # add max prob
        res['pred_proba_max'] = np.max(y_proba, axis=1)
    st.dataframe(res.head(200))

    # Download results & model
    buf = io.BytesIO()
    res.to_csv(buf, index=False)
    buf.seek(0)
    st.download_button('Download hasil prediksi (CSV)', data=buf, file_name='hasil_prediksi.csv', mime='text/csv')

    save_model = st.checkbox('Simpan model dan scaler ke file (.joblib)')
    if save_model:
        save_obj = {'model': model, 'scaler': scaler, 'label_encoder': le, 'features': selected_features}
        joblib.dump(save_obj, 'model_jenis_obat.joblib')
        st.success('Model disimpan sebagai model_jenis_obat.joblib')

    st.success('Selesai pelatihan. Ingat: aplikasi ini untuk demo. Analisis nyata butuh validasi domain expert.')

else:
    st.info('Klik "Latih model" di sidebar untuk memulai pelatihan. Anda juga dapat memasukkan SMILES di sidebar untuk prediksi cepat (setelah model dilatih).')

# Quick-predict dari SMILES (jika user masukkan beberapa SMILES di sidebar)
if smiles_input.strip() and RDKit_AVAILABLE:
    st.subheader('Prediksi cepat dari SMILES yang dimasukkan')
    smi_lines = [s.strip() for s in smiles_input.splitlines() if s.strip()]
    descs = []
    for smi in smi_lines:
        d = rdkit_descriptors_from_smiles(smi)
        if d is None:
            descs.append(None)
        else:
            descs.append(d)
    smi_df = pd.DataFrame([d for d in descs if d is not None])
    if smi_df.empty:
        st.error('Tidak ada SMILES valid untuk diprediksi.')
    else:
        # select features & scale consistent with training if exists
        try:
            obj = joblib.load('model_jenis_obat.joblib')
            model_loaded = obj['model']
            scaler_loaded = obj.get('scaler', None)
            features_loaded = obj['features']
            le_loaded = obj.get('label_encoder', le)
            X_pred = smi_df[features_loaded].fillna(smi_df[features_loaded].median())
            if scaler_loaded:
                X_pred_s = scaler_loaded.transform(X_pred)
            else:
                X_pred_s = X_pred.values
            if hasattr(model_loaded, 'predict_proba'):
                p = model_loaded.predict_proba(X_pred_s)
                preds = model_loaded.predict(X_pred_s)
            else:
                preds = np.argmax(model_loaded.predict(X_pred_s), axis=1)
                p = None
            pred_labels = [le_loaded.inverse_transform([int(v)])[0] for v in preds]
            out = pd.DataFrame({'SMILES': [s for s in smi_lines[:len(pred_labels)]], 'predicted': pred_labels})
            if p is not None:
                out['pred_proba_max'] = np.max(p, axis=1)
            st.dataframe(out)
        except Exception as e:
            st.error('Model tersimpan tidak ditemukan. Jalankan pelatihan dan centang "Simpan model" untuk mengaktifkan prediksi cepat. Error: '+str(e))

# Footer
st.markdown('---')
st.markdown('**Catatan:** Ini aplikasi demo. Untuk pemakaian riset/klinis nyata, gunakan dataset valid, preprocessing kimia yang lengkap (fingerprints, graf neural networks), dan review domain expert.')